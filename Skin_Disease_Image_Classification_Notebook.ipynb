{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Skin Disease Image Classification Notebook\n",
        "\n",
        "In this notebook, we're making an image classifier which can classify six skin diseases: \n",
        "* Acne and Rosacea\n",
        "* Atopic Dermatitis\n",
        "* Herpes HPV and other STD\n",
        "* Poison Ivy and other Contact Diseases\n",
        "* Psoriasis or Lichen\n",
        "* Scabies Lyme Disease and other Infestations and Bites\n",
        " \nThe full dataaset can be found here https://www.kaggle.com/datasets/shubhamgoel27/dermnet\n",
        "\n",
        "Sometimes these skin deseases look similar and indistinguishable with the regular symptoms such as rashes and redish. \n",
        "\n",
        "Can we use deep learning to classify these deseases? What model architecture should we use? How should we train our models? This project hopes to answer these questions/"
      ],
      "metadata": {
        "id": "gI5cH_9bO7Ao"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bi2Jz96CIkf6"
      },
      "source": [
        "#Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dCYyKRWmEBO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "import random\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten,Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Sequential\n",
        "from google.cloud import storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7FXtkjoODaP"
      },
      "source": [
        "# Download DATASET\n",
        "You can choose between this two methods below "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ksUHxQ1egka"
      },
      "source": [
        "## Google Drive\n",
        "Google Drive is faster to use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7pL7-xThEl6",
        "outputId": "16039c45-9782-4467-957f-b53362e65545"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving folder list\n",
            "Processing file 1fumMrJhoBGfqZtrcnBOAvngpjxND49Hp image_dataset.zip\n",
            "Retrieving folder list completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1fumMrJhoBGfqZtrcnBOAvngpjxND49Hp\n",
            "To: /content/Dataset/image_dataset.zip\n",
            "100% 462M/462M [00:06<00:00, 73.7MB/s]\n",
            "Download completed\n"
          ]
        }
      ],
      "source": [
         "# TO RUN THIS LOCALLY MAKE SURE YOU INSTALL THE MODULE FIRST\n",
        "import gdown\n",
        "!gdown --folder https://drive.google.com/drive/folders/1uRPA1LJPmc6QHp-IGVdpcMYz52daxBxF?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bULl8rF0qW2"
      },
      "outputs": [],
      "source": [
        "#Mounting BANGKIT GDrive\n",
        "\n",
        "# Change the PATH with ur own DATASET location\n",
        "# Shared Gdrive for Dataset https://drive.google.com/drive/folders/1oYBG6KJSZjtlSF3wy7eb-KZF66J070Zc?usp=sharing\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wn66VAeTuPg-"
      },
      "source": [
        "## Unzipping The file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEaEOuzquOUj"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "# Change the PATH for with your own Directory\n",
        "filename = '/content/Dataset/image_dataset.zip'\n",
        "shutil.unpack_archive(filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1feIl9cEen00"
      },
      "source": [
        "## Google Cloud"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TO RUN THIS LOCALLY MAKE SURE YOU INSTALL THE MODULE FIRST\n",
        "# Downloading TRAIN dataset\n",
        "import gsutil\n",
        "!gsutil cp -r gs://c22ps191b2/dataset/Train/ ."
      ],
      "metadata": {
        "id": "YKlxUlwaP_RL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download TEST dataset\n",
        "!gsutil cp -r gs://c22ps191b2/dataset/Test/ ."
      ],
      "metadata": {
        "id": "EmLaQz28Jlez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBPE5u69OJAa"
      },
      "source": [
        "# TEST DISPLAY DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MirwdT2smEBQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be45c2e0-1847-4dd3-bfaa-059884a7c1fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ],
            "image/png": "gs://c22ps191b2/dataset/Train/Acne and Rosacea Photos/07Acne081101.jpg"
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#Test Display\n",
        "# Change the PATH with ur own DATASET location\n",
        "from IPython.display import Image\n",
        "Image(\"/content/drive/MyDrive/Datasets/Train/Acne and Rosacea Photos/07Acne081101.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CKNQZLFa0d8"
      },
      "outputs": [],
      "source": [
        "# Test Display (2)\n",
        "# Change the PATH with ur own DATASET location\n",
        "plt.figure(figsize=(20,20))\n",
        "test_folder=r'/content/drive/MyDrive/Datasets/Test/Acne and Rosacea Photos'\n",
        "for i in range(5):\n",
        "    file = random.choice(os.listdir(test_folder))\n",
        "    image_path= os.path.join(test_folder, file)\n",
        "    img=mpimg.imread(image_path)\n",
        "    ax=plt.subplot(1,5,i+1)\n",
        "    ax.title.set_text(file)\n",
        "    plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpF3RMNJkoYy",
        "outputId": "aa3a3f37-5b43-4b11-cf03-a30a4e94c499"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Contents of base directory:\n",
            "['Test', 'Train', 'class_list.txt']\n",
            "\n",
            "Contents of train directory:\n",
            "['Poison Ivy Photos and other Contact Dermatitis', 'Herpes HPV and other STDs Photos', 'Acne and Rosacea Photos', 'Atopic Dermatitis Photos', 'Scabies Lyme Disease and other Infestations and Bites', 'Psoriasis pictures Lichen Planus and related diseases']\n",
            "\n",
            "Contents of validation directory:\n",
            "['Poison Ivy Photos and other Contact Dermatitis', 'Psoriasis pictures Lichen Planus and related diseases', 'Acne and Rosacea Photos', 'Atopic Dermatitis Photos', 'Scabies Lyme Disease and other Infestations and Bites', 'Herpes HPV and other STDs Photos']\n"
          ]
        }
      ],
      "source": [
        "# Change the PATH with ur own DATASET location\n",
        "base_dir = '/content/drive/MyDrive/Datasets'\n",
        "\n",
        "print(\"Contents of base directory:\")\n",
        "print(os.listdir(base_dir))\n",
        "\n",
        "print(\"\\nContents of train directory:\")\n",
        "print(os.listdir(f'{base_dir}/Train'))\n",
        "\n",
        "print(\"\\nContents of validation directory:\")\n",
        "print(os.listdir(f'{base_dir}/Test'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-e07LyrVOOWW"
      },
      "source": [
        "# Data Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQ8KwFVx4axE"
      },
      "outputs": [],
      "source": [
        "# Change the PATH with ur own DATASET location\n",
        "train_path=\"/content/drive/MyDrive/Datasets/Train\"\n",
        "test_path=\"/content/drive/MyDrive/Datasets/Test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1tOjVR9uK8r"
      },
      "outputs": [],
      "source": [
        "x_train=[]\n",
        "\n",
        "for folder in os.listdir(train_path):\n",
        "\n",
        "    sub_path=train_path+\"/\"+folder\n",
        "\n",
        "    for img in os.listdir(sub_path):\n",
        "\n",
        "        image_path=sub_path+\"/\"+img\n",
        "\n",
        "        img_arr=cv2.imread(image_path)\n",
        "\n",
        "        img_arr=cv2.resize(img_arr,(150,150))\n",
        "\n",
        "        x_train.append(img_arr)\n",
        "\n",
        "x_test=[]\n",
        "\n",
        "for folder in os.listdir(test_path):\n",
        "\n",
        "    sub_path=test_path+\"/\"+folder\n",
        "\n",
        "    for img in os.listdir(sub_path):\n",
        "\n",
        "        image_path=sub_path+\"/\"+img\n",
        "\n",
        "        img_arr=cv2.imread(image_path)\n",
        "\n",
        "        img_arr=cv2.resize(img_arr,(150,150))\n",
        "\n",
        "        x_test.append(img_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOo1M822uvj1"
      },
      "outputs": [],
      "source": [
        "train_x=np.array(x_train)\n",
        "test_x=np.array(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "te3bncE1uxgf"
      },
      "outputs": [],
      "source": [
        "train_x=train_x/255.0\n",
        "test_x=test_x/255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTSLDm_4u0OB"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a0l7khiu5xQ",
        "outputId": "10b58e44-9be9-4321-bbcb-3b58cabc6840"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3693 images belonging to 6 classes.\n",
            "Found 1058 images belonging to 6 classes.\n"
          ]
        }
      ],
      "source": [
        "training_set = train_datagen.flow_from_directory(train_path,\n",
        "                                                 target_size = (150, 150),\n",
        "                                                 batch_size = 10,\n",
        "                                                 class_mode = 'sparse')\n",
        "test_set = test_datagen.flow_from_directory(test_path,\n",
        "                                            target_size = (150, 150),\n",
        "                                            batch_size = 10,\n",
        "                                            class_mode = 'sparse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keJAKel9u_yW"
      },
      "outputs": [],
      "source": [
        "train_y=training_set.classes\n",
        "test_y=test_set.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjGotJ87vFow",
        "outputId": "4715e538-4bdb-435c-c837-1d56aadd5174"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Acne and Rosacea Photos': 0,\n",
              " 'Atopic Dermatitis Photos': 1,\n",
              " 'Herpes HPV and other STDs Photos': 2,\n",
              " 'Poison Ivy Photos and other Contact Dermatitis': 3,\n",
              " 'Psoriasis pictures Lichen Planus and related diseases': 4,\n",
              " 'Scabies Lyme Disease and other Infestations and Bites': 5}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_set.class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kG6jCkenvHrv",
        "outputId": "590f310b-2776-42c7-a801-6777cddcede6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((3693,), (1058,))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_y.shape,test_y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGlieogBfYUm"
      },
      "source": [
        "# MODELLING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmdtxti-viA6"
      },
      "outputs": [],
      "source": [
        "def create_model():      \n",
        "\n",
        "  # Define the model\n",
        "  model = tf.keras.models.Sequential([ \n",
        "    tf.keras.layers.Conv2D(128,(3,3), activation = 'relu', input_shape=(150,150,3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128,(3,3), activation = 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(512, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(6, activation='softmax')\n",
        "  ])\n",
        "  \n",
        "\n",
        "  model.compile(optimizer = RMSprop(learning_rate=0.001),\n",
        "                loss =  'sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "     \n",
        "  \n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHKBX5i9OXkY"
      },
      "source": [
        "# COMPILING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CB14zaQuvlOn"
      },
      "outputs": [],
      "source": [
        "model = create_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1NZUDoQvWT3"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "  loss='sparse_categorical_crossentropy',\n",
        "  optimizer=\"adam\",\n",
        "  metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hp0qC6j5v-DB"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "  train_x,\n",
        "  train_y,\n",
        "  epochs=50,\n",
        "  batch_size=32,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0GHTwmdzWzH"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
        "import numpy as np\n",
        "#predict\n",
        "y_pred=model.predict(test_x)\n",
        "y_pred=np.argmax(y_pred,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6tHg5Kzzbe1",
        "outputId": "23283669-7392-4591-8169-07426e8ac5da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.20      0.29      0.24       214\n",
            "           1       0.09      0.05      0.07       206\n",
            "           2       0.02      0.01      0.02       144\n",
            "           3       0.00      0.00      0.00        30\n",
            "           4       0.31      0.27      0.29       406\n",
            "           5       0.07      0.14      0.10        58\n",
            "\n",
            "    accuracy                           0.18      1058\n",
            "   macro avg       0.12      0.13      0.12      1058\n",
            "weighted avg       0.18      0.18      0.18      1058\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#get classification report\n",
        "print(classification_report(y_pred,test_y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jM_oJvgwzdfs",
        "outputId": "767b26b4-877f-438c-b653-5acf530de9f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 62  23  47   3  46  33]\n",
            " [ 13  11  51  54  73   4]\n",
            " [ 28   7   2   5  97   5]\n",
            " [ 10   2   1   0  15   2]\n",
            " [169  69   1   2 109  56]\n",
            " [ 26  11   0   1  12   8]]\n"
          ]
        }
      ],
      "source": [
        "#get confusion matrix\n",
        "print(confusion_matrix(y_pred,test_y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_hSRWHvOipJ"
      },
      "source": [
        "# Model Testing\n",
        "\n",
        "Referensi https://www.geeksforgeeks.org/python-image-classification-using-keras/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "eAkJ5xJJoHon",
        "outputId": "62536cbf-a571-4e74-ea62-361b637af5d6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0bf6f539-4fc2-4dbd-be26-6c227a0d37e0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0bf6f539-4fc2-4dbd-be26-6c227a0d37e0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving Lichen-Nitidus-3.jpg to Lichen-Nitidus-3.jpg\n",
            "[2.3164639e-01 5.1888373e-06 2.7756953e-06 5.1630114e-04 7.6782840e-01\n",
            " 8.7890504e-07]\n",
            "Psoriasis\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img(path, target_size=(150, 150))\n",
        "  x = image.img_to_array(img)\n",
        "  x = x / 255\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  print(classes[0])\n",
        "  if max(classes[0])==classes[0][0]:\n",
        "    print(\"Acne and Rosacea\")\n",
        "  elif max(classes[0])==classes[0][1]:\n",
        "    print(\"Atopic Dermatitis\")\n",
        "  elif max(classes[0])==classes[0][2]:\n",
        "    print(\"Herpes HPV and other STD\")\n",
        "  elif max(classes[0])==classes[0][3]:\n",
        "    print(\"Poison Ivy and other contact diseases\")\n",
        "  elif max(classes[0])==classes[0][4]:\n",
        "    print(\"Psoriasis or Lichen\")\n",
        "  elif max(classes[0])==classes[0][5]:\n",
        "    print(\"Scabies Lyme Disease and other infestations and bites\")  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrEHCj0ZI_EZ"
      },
      "source": [
        "# Save the Model\n",
        "\n",
        "To load the trained model into TensorFlow Serving we first need to save it in the [SavedModel](https://www.tensorflow.org/guide/saved_model) format.  This will create a protobuf file in a well-defined directory hierarchy, and will include a version number.  [TensorFlow Serving](https://www.tensorflow.org/tfx/serving/serving_config) allows us to select which version of a model, or \"servable\" we want to use when we make inference requests.  Each version will be exported to a different sub-directory under the given path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OIxd0LIDbQl"
      },
      "outputs": [],
      "source": [
        "# JALANIN\n",
        "# Save the trained model as a Keras HDF5 file. \n",
        "import time\n",
        "saved_model_path = \"./my_model.h5\"#.format(int(time.time()))\n",
        "\n",
        "model.save(saved_model_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ckr24fB1Rz1"
      },
      "source": [
        "##TF LITE CONVERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kx58oT9v1d_b",
        "outputId": "a0c8a0c8-c0de-4124-874a-1f0e7df98d5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmps98mhydh/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmps98mhydh/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tf_litemodel = converter.convert()\n",
        "\n",
        "with open('model.tflite','wb') as f:\n",
        "  f.write(tf_litemodel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQTEAyV3s5Qg"
      },
      "source": [
        "# Converting the model to TFJS\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOXS4OfWokfv"
      },
      "outputs": [],
      "source": [
        "#!pip install tensorflow==2.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I011wOlTr4ZM"
      },
      "outputs": [],
      "source": [
        "#!pip install tensorflowjs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kx3XGJkHrWtd",
        "outputId": "e9268557-db53-4066-afd2-9b13a183feb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â€¢ Using TensorFlow Version: 2.8.2\n"
          ]
        }
      ],
      "source": [
        "#print('\\u2022 Using TensorFlow Version:', tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3p-hEqNnoYqY"
      },
      "outputs": [],
      "source": [
        "# Use the tensorflow.js converter to convert the saved Keras model into JSON format.\n",
        "\n",
        "!tensorflowjs_converter --input_format=keras {saved_model_path} ./"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Skin Disease Image Classification Notebook.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "0e091db8d58018cc79bd95d4c344ae6fb50dc1dda4747c0206fad4c7e07cd6fa"
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
